{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove():\n",
    "    glove_home = './'\n",
    "    words_to_load = 50000\n",
    "\n",
    "    with open(glove_home + 'glove.6B.50d.txt',encoding='utf-8') as f:\n",
    "        loaded_embeddings = np.zeros((words_to_load, 50))\n",
    "        words = {}\n",
    "        idx2words = {}\n",
    "        ordered_words = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "            words[s[0]] = i\n",
    "            idx2words[i] = s[0]\n",
    "            ordered_words.append(s[0])\n",
    "    return loaded_embeddings, words, idx2words, ordered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        \n",
    "        text = re.sub(r\"\\.{3}\", \" <DASH>\", text)\n",
    "        text = re.sub(r\"\\.{1}\", \" <PERIOD>\", text)\n",
    "        text = re.sub(r\"\\,\", \" <COMMA>\", text)\n",
    "        text = re.sub(r\"\\?\", \" <QUSTIONMARK>\", text)\n",
    "        text = re.sub(r\"\\!\", \" <EXCLAMATIONMARK>\", text)\n",
    "        \n",
    "        paragraphs = text.split('\\n')\n",
    "        lines = []\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            lines_in_paragraph = [line.strip() + \" <PERIOD>\" for line in paragraph.split('<PERIOD>') if line.strip()!=\"\"]\n",
    "            lines += lines_in_paragraph\n",
    "        return lines\n",
    "    return None\n",
    "        \n",
    "def build_dictionary(lines):\n",
    "    word_set = set()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        tokens = tokenize(line)\n",
    "        word_set = word_set | set(tokens)\n",
    "        lines[i] = tokens\n",
    "    word_set = word_set - set([''])\n",
    "    vocabulary = list(word_set)\n",
    "    vocabulary = [\"<0>\", \"<ENDOFLINE>\", \"<UNKNOWN>\", \"<PADDING>\"] + vocabulary\n",
    "    dictionary = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "    idx_lines = []\n",
    "    for line in lines:\n",
    "        idx_lines.append([dictionary[word] for word in line if word!=\"\"]+[1])\n",
    "    lines = []\n",
    "    for line in idx_lines:\n",
    "        if len(line) > 0:\n",
    "            lines.append(line)\n",
    "    return lines, vocabulary, dictionary\n",
    "\n",
    "def tokenize(line):\n",
    "    tokens = line.split(' ')\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].strip('\\'').lower()\n",
    "    return tokens\n",
    "\n",
    "def get_rand_line(lines):\n",
    "    return lines[random.randint(0, len(lines)-1)]\n",
    "\n",
    "def cosine_similarity(vec_one, vec_two):\n",
    "    return torch.dot(vec_one, vec_two)/torch.norm(vec_one)/torch.norm(vec_two)\n",
    "\n",
    "def build_preloadembed(vocabulary, loaded_embeddings,embedding_dim, words, ordered_words):\n",
    "    preloadembed = torch.zeros((len(vocabulary), embedding_dim)).normal_(mean=0,std=0.01)\n",
    "    for i in range(len(vocabulary)):\n",
    "        word = vocabulary[i]\n",
    "        if word in ordered_words:\n",
    "            preloadembed[i, :] = torch.from_numpy(loaded_embeddings[words[word]])\n",
    "    return preloadembed\n",
    "\n",
    "class Dataloader():\n",
    "    def __init__(self, minibatch_size, minibatch_num, lines):\n",
    "        super(Dataloader, self).__init__()\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.minibatch_num = minibatch_num\n",
    "        self.lines = lines\n",
    "    \n",
    "    def get_minibatches(self):\n",
    "        chosen_idxs = np.random.randint(len(lines), size = self.minibatch_size*self.minibatch_num)\n",
    "        chosen_lines = [lines[chosen_idx] for chosen_idx in chosen_idxs]\n",
    "        chosen_lines.sort(key=lambda x:len(x))\n",
    "        minibatches = []\n",
    "        for i in range(self.minibatch_num):\n",
    "            mini_batch_content = chosen_lines[i*self.minibatch_size:(i+1)*self.minibatch_size]\n",
    "            max_length = len(mini_batch_content[-1])\n",
    "            for i in range(len(mini_batch_content)):\n",
    "                while len(mini_batch_content[i])<max_length:\n",
    "                    mini_batch_content[i].append(3)\n",
    "            minibatches.append(torch.LongTensor(mini_batch_content))\n",
    "        return minibatches\n",
    "\n",
    "class LSTM3(nn.Module):\n",
    "    def __init__(self, preloadembed, vocabulary, dictionary, embedding_dim, hidden_size, batch_size):\n",
    "        super(LSTM3, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocabulary), embedding_dim, padding_idx=0)\n",
    "        self.embedding_size = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocabulary = vocabulary\n",
    "        self.dictionary = dictionary\n",
    "        self.batch_size = batch_size\n",
    "        #self.embed.weight.data.copy_(torch.rand(self.embed.weight.size()))\n",
    "        self.embed.weight.data.copy_(preloadembed)\n",
    "        del preloadembed\n",
    "        \n",
    "        self.linear_f0 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_i0 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_ctilde0 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_o0 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        \n",
    "        self.linear_f1 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_i1 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_ctilde1 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_o1 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        \n",
    "        self.linear_f2 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_i2 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_ctilde2 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.linear_o2 = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        \n",
    "        self.decoder0 = nn.Linear(hidden_size, int((hidden_size+embedding_dim)*0.5))\n",
    "        self.decoder1 = nn.Linear(int((hidden_size+embedding_dim)*0.5), embedding_dim)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def find_nearest_word(self, output, k=1):\n",
    "        scored_words = [(word, cosine_similarity(output, self.embed(torch.LongTensor([word])).squeeze())) for word in range(len(self.vocabulary))]\n",
    "        sorted_words = sorted(scored_words, key=itemgetter(1), reverse=True)\n",
    "        return sorted_words[:k]\n",
    "    \n",
    "    def forward(self, line, hidden, c0, c1, c2):\n",
    "        line_emb = self.embed(line)\n",
    "        line_embs = torch.chunk(line_emb, line_emb.size()[1], 1)\n",
    "        output_line = []\n",
    "        loss = 0\n",
    "        \n",
    "        def step(emb, hid, c_t0, c_t1, c_t2):\n",
    "            combined = torch.cat((hid, emb), 1)\n",
    "            f0 = torch.sigmoid(self.linear_f0(combined))\n",
    "            i0 = torch.sigmoid(self.linear_i0(combined))\n",
    "            c_tilde0 = torch.tanh(self.linear_ctilde0(combined))\n",
    "            c_t0 = f0 * c_t0 + i0 * c_tilde0\n",
    "            o0 = torch.sigmoid(self.linear_o0(combined))\n",
    "            hid0 = o0 * torch.tanh(c_t0)\n",
    "            \n",
    "            combined = torch.cat((hid0, emb), 1)\n",
    "            f1 = torch.sigmoid(self.linear_f1(combined))\n",
    "            i1 = torch.sigmoid(self.linear_i1(combined))\n",
    "            c_tilde1 = torch.tanh(self.linear_ctilde1(combined))\n",
    "            c_t1 = f1 * c_t1 + i1 * c_tilde1\n",
    "            o1 = torch.sigmoid(self.linear_o1(combined))\n",
    "            hid1 = o1 * torch.tanh(c_t1)\n",
    "            \n",
    "            combined = torch.cat((hid1, emb), 1)\n",
    "            f2 = torch.sigmoid(self.linear_f2(combined))\n",
    "            i2 = torch.sigmoid(self.linear_i2(combined))\n",
    "            c_tilde2 = torch.tanh(self.linear_ctilde2(combined))\n",
    "            c_t2 = f2 * c_t2 + i2 * c_tilde2\n",
    "            o2 = torch.sigmoid(self.linear_o2(combined))\n",
    "            hid2 = o2 * torch.tanh(c_t2)\n",
    "            return hid2, c_t0, c_t1, c_t2\n",
    "              \n",
    "        for i in range(len(line_embs)-1):\n",
    "            hidden, c0, c1, c2 = step(line_embs[i].squeeze(), hidden, c0, c1, c2)\n",
    "            output = self.decoder0(hidden)\n",
    "            output = self.decoder1(output)\n",
    "            for b in range(2, self.batch_size):\n",
    "                #loss += cosine_similarity(output[b,:].squeeze(), line_embs[i+1].squeeze()[b,:])\n",
    "                loss += 1-cosine_similarity(output[b,:].squeeze(), line_embs[i+1].squeeze()[b,:])\n",
    "            output_line.append(output)\n",
    "            \"\"\"\n",
    "            if i == 2:\n",
    "                nearest_word = self.find_nearest_word(output[2,:].squeeze())\n",
    "                nearest_word1 = self.find_nearest_word(line_embs[i+1].squeeze()[2,:])\n",
    "                print(self.vocabulary[nearest_word[0][0]], self.vocabulary[nearest_word1[0][0]])\n",
    "            \"\"\"                   \n",
    "            \n",
    "        return output_line, loss\n",
    "    \n",
    "    def babble_mode(self, max_length):\n",
    "        output_line = []\n",
    "        hidden, c0, c1, c2 = torch.zeros(self.hidden_size).normal_(mean=0,std=.1), torch.zeros(self.hidden_size).normal_(mean=0,std=.1), torch.zeros(self.hidden_size).normal_(mean=0,std=.1), torch.zeros(self.hidden_size).normal_(mean=0,std=.1)\n",
    "        output = self.decoder0(hidden)\n",
    "        output = self.decoder1(output)\n",
    "            \n",
    "        def step(emb, hid, c_t0, c_t1, c_t2):\n",
    "            combined = torch.cat((hid, emb), 0)\n",
    "            f0 = torch.sigmoid(self.linear_f0(combined))\n",
    "            i0 = torch.sigmoid(self.linear_i0(combined))\n",
    "            c_tilde0 = torch.tanh(self.linear_ctilde0(combined))\n",
    "            c_t0 = f0 * c_t0 + i0 * c_tilde0\n",
    "            o0 = torch.sigmoid(self.linear_o0(combined))\n",
    "            hid0 = o0 * torch.tanh(c_t0)\n",
    "            \n",
    "            combined = torch.cat((hid0, emb), 0)\n",
    "            f1 = torch.sigmoid(self.linear_f1(combined))\n",
    "            i1 = torch.sigmoid(self.linear_i1(combined))\n",
    "            c_tilde1 = torch.tanh(self.linear_ctilde1(combined))\n",
    "            c_t1 = f1 * c_t1 + i1 * c_tilde1\n",
    "            o1 = torch.sigmoid(self.linear_o1(combined))\n",
    "            hid1 = o1 * torch.tanh(c_t1)\n",
    "            \n",
    "            combined = torch.cat((hid1, emb), 0)\n",
    "            f2 = torch.sigmoid(self.linear_f2(combined))\n",
    "            i2 = torch.sigmoid(self.linear_i2(combined))\n",
    "            c_tilde2 = torch.tanh(self.linear_ctilde2(combined))\n",
    "            c_t2 = f2 * c_t2 + i2 * c_tilde2\n",
    "            o2 = torch.sigmoid(self.linear_o2(combined))\n",
    "            hid2 = o2 * torch.tanh(c_t2)\n",
    "            return hid2, c_t0, c_t1, c_t2\n",
    "              \n",
    "        for i in range(max_length):\n",
    "            hidden, c0, c1, c2 = step(output, hidden, c0, c1, c2)\n",
    "            output = self.decoder0(hidden)\n",
    "            output = self.decoder1(output)\n",
    "            nearest_word = self.find_nearest_word(output)\n",
    "            word = self.vocabulary[nearest_word[0][0]]\n",
    "            output_line.append(word)\n",
    "            if word == \"<ENDOFLINE>\":\n",
    "                break\n",
    "            line = \"\"\n",
    "            for word in output_line:\n",
    "                line += word + \" \"\n",
    "        return line\n",
    "            \n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = torch.ones(self.batch_size, self.hidden_size).normal_(mean=0,std=.1)\n",
    "        c0 = torch.ones(self.batch_size, self.hidden_size).normal_(mean=0,std=.1)\n",
    "        c1 = torch.ones(self.batch_size, self.hidden_size).normal_(mean=0,std=.1)\n",
    "        c2 = torch.ones(self.batch_size, self.hidden_size).normal_(mean=0,std=.1)\n",
    "        return h0, c0, c1, c2\n",
    "    \n",
    "    def init_weights(self):\n",
    "        #initrange = 0.1\n",
    "        lin_layers = [self.linear_f0, self.linear_i0, self.linear_ctilde0, self.linear_o0,\n",
    "                      self.linear_f1, self.linear_i1, self.linear_ctilde1, self.linear_o1,\n",
    "                      self.linear_f2, self.linear_i2, self.linear_ctilde2, self.linear_o2,\n",
    "                      self.decoder0, self.decoder1]\n",
    "        #em_layer = [self.embed]\n",
    "        em_layer = []\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.normal_(0, 0.1)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare time: 4.68490743637085\n",
      "epoch 0 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [01:56<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9810074776649476\n",
      "epoch 1 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [01:54<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3060655040144917\n",
      "epoch 2 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [01:55<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0142407584428788\n",
      "epoch 3 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [01:57<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.823183552622795\n",
      "epoch 4 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:01<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6853950708031653\n",
      "epoch 5 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:08<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5474228750050067\n",
      "epoch 6 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:06<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3961868312954901\n",
      "epoch 7 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:06<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2873744143664836\n",
      "epoch 8 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:04<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.208361787635088\n",
      "epoch 9 start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [02:06<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1034245105326177\n",
      "training time 1218.9023954868317\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 10\n",
    "minibatch_num = 1000\n",
    "epoch = 10\n",
    "embedding_dim = 50\n",
    "hidden_size = 20\n",
    "\n",
    "time1 = time.time()\n",
    "loaded_embeddings, words, idx2words, ordered_words = load_glove()\n",
    "lines = load_data(\"Life is Magic.txt\")\n",
    "lines, vocabulary, dictionary = build_dictionary(lines)\n",
    "loader = Dataloader(minibatch_size, minibatch_num, lines)\n",
    "preloadembed = build_preloadembed(vocabulary, loaded_embeddings,embedding_dim, words, ordered_words)\n",
    "\n",
    "\n",
    "rnn = LSTM3(preloadembed, vocabulary, dictionary, embedding_dim, hidden_size, minibatch_size)\n",
    "rnn.init_weights()\n",
    "\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr= 0.001, momentum=0.9)\n",
    "\n",
    "time2 = time.time()\n",
    "print(\"prepare time:\",time2-time1)\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(\"epoch\",e,\"start!\")\n",
    "    minibatches = loader.get_minibatches()\n",
    "    loss_sum = 0\n",
    "    for b in tqdm(range(minibatch_num)):\n",
    "        hidden, c1, c2, c3 = rnn.init_hidden()\n",
    "        output_line, loss = rnn(minibatches[b],  hidden, c1, c2, c3)\n",
    "        loss.backward()\n",
    "        loss_sum += float(loss.item())\n",
    "        torch.nn.utils.clip_grad_norm_(rnn.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "    print(loss_sum/minibatch_num/minibatch_size)\n",
    "\n",
    "time3 = time.time()\n",
    "print(\"training time\",time3-time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facial fluttershy—both chest grimace trembling grimace cheerfulness glared \"each \"sorry glared tower's glared \"each grimace glared tower's glared \"each grimace \n",
      "babble time 8.899682760238647\n"
     ]
    }
   ],
   "source": [
    "babble = rnn.babble_mode(20)\n",
    "print(babble)\n",
    "time4 = time.time()\n",
    "print(\"babble time\",time4-time3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
